{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's see how to use DBT to:\n",
    "# 1: train a VGG-like network on CIFAR-10\n",
    "# 2: continue a train from the last iteration\n",
    "# 3: do TRANSFER LEARNING from the trained model to another model that will be able to classify CIFAR-100\n",
    "# 4: do FINE TUNING of the model trained on CIFAR-10 to solve the CIFAR-100 classification problem\n",
    "# 5: compare the train/validation/test performance of the models\n",
    "\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "from dytb.inputs.predefined import Cifar10, Cifar100\n",
    "from dytb.train import train\n",
    "from dytb.models.predefined.VGG import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "vgg = VGG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the CIFAR-10 input source\n",
    "cifar10 = Cifar10.Cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-22 11:03:34.528382: step 0, loss = 2.4389 (22.1 examples/sec; 2.262 sec/batch)\n",
      "2017-03-22 11:03:40.453107: step 100, loss = 2.3493 (877.2 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:03:46.303900: step 200, loss = 2.3435 (886.9 examples/sec; 0.056 sec/batch)\n",
      "2017-03-22 11:03:52.140747: step 300, loss = 1.9785 (874.9 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:03:57.979964: step 400, loss = 2.0475 (881.1 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:04:03.845082: step 500, loss = 1.8387 (891.0 examples/sec; 0.056 sec/batch)\n",
      "2017-03-22 11:04:09.663344: step 600, loss = 1.7706 (880.7 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:04:15.484470: step 700, loss = 1.7600 (884.0 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:04:21.333627: step 800, loss = 1.8535 (892.4 examples/sec; 0.056 sec/batch)\n",
      "2017-03-22 11:04:27.159882: step 900, loss = 1.5366 (884.8 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:04:33.027119: step 1000, loss = 1.6242 (877.1 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:04:36.863376 (1): train accuracy = 0.420 validation accuracy = 0.349\n"
     ]
    }
   ],
   "source": [
    "# 1: Train VGG on Cifar10 for an Epoch\n",
    "\n",
    "# Place the train process on GPU:0\n",
    "device = '/gpu:0'\n",
    "with tf.device(device):\n",
    "    info = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar10,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        force_restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.3487</td>\n",
       "      <td>0.3531</td>\n",
       "      <td>0.3487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test   train  validation\n",
       "accuracy  0.3487  0.3531      0.3487"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Info containes every information related to the trained model.\n",
    "# We're interested in stats only, thus we extract only them from the info dict\n",
    "# Display the results in a table. Let's use a Pandas DataFrame for that\n",
    "\n",
    "# Extract the accuracyes measured in every set (train/validation/test)\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in info[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1690</td>\n",
       "      <td>516</td>\n",
       "      <td>380</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>38</td>\n",
       "      <td>147</td>\n",
       "      <td>1419</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>3467</td>\n",
       "      <td>18</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>106</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>451</td>\n",
       "      <td>21</td>\n",
       "      <td>726</td>\n",
       "      <td>558</td>\n",
       "      <td>19</td>\n",
       "      <td>1833</td>\n",
       "      <td>862</td>\n",
       "      <td>258</td>\n",
       "      <td>87</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "      <td>218</td>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "      <td>3678</td>\n",
       "      <td>180</td>\n",
       "      <td>230</td>\n",
       "      <td>34</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>18</td>\n",
       "      <td>461</td>\n",
       "      <td>491</td>\n",
       "      <td>69</td>\n",
       "      <td>1742</td>\n",
       "      <td>1215</td>\n",
       "      <td>563</td>\n",
       "      <td>70</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>164</td>\n",
       "      <td>255</td>\n",
       "      <td>5</td>\n",
       "      <td>4015</td>\n",
       "      <td>148</td>\n",
       "      <td>275</td>\n",
       "      <td>9</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>318</td>\n",
       "      <td>635</td>\n",
       "      <td>14</td>\n",
       "      <td>2256</td>\n",
       "      <td>1418</td>\n",
       "      <td>160</td>\n",
       "      <td>21</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78</td>\n",
       "      <td>21</td>\n",
       "      <td>174</td>\n",
       "      <td>197</td>\n",
       "      <td>15</td>\n",
       "      <td>2106</td>\n",
       "      <td>104</td>\n",
       "      <td>1997</td>\n",
       "      <td>32</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>851</td>\n",
       "      <td>1056</td>\n",
       "      <td>165</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>2205</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>2467</td>\n",
       "      <td>22</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>181</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1    2    3   4     5     6     7     8     9\n",
       "0  1690   516  380  164   0   264    38   147  1419   380\n",
       "1    31  3467   18   54   0    89     2    70   106  1154\n",
       "2   451    21  726  558  19  1833   862   258    87   148\n",
       "3    82    12  218  368   1  3678   180   230    34   190\n",
       "4   250    18  461  491  69  1742  1215   563    70   143\n",
       "5    49     5  164  255   5  4015   148   275     9    96\n",
       "6    48    11  318  635  14  2256  1418   160    21   162\n",
       "7    78    21  174  197  15  2106   104  1997    32   301\n",
       "8   851  1056  165  114   0   111     4    34  2205   397\n",
       "9    57  2467   22   93   0   144     1   244   181  1798"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the confusion matrices \n",
    "confusion_matrices = {key: value[\"confusion_matrix\"] for key, value in info[\"stats\"].items() if type(value) is dict}\n",
    "# Display the confusione matrices for the training set\n",
    "df = pd.DataFrame(confusion_matrices[\"train\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-22 11:05:34.374507: step 1100, loss = 1.4109 (886.4 examples/sec; 0.056 sec/batch)\n",
      "2017-03-22 11:05:40.311744: step 1200, loss = 1.3996 (883.7 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:05:46.183052: step 1300, loss = 1.4360 (879.2 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:05:52.039435: step 1400, loss = 1.7960 (880.8 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:05:57.873782: step 1500, loss = 1.2612 (874.2 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:06:03.717252: step 1600, loss = 1.4995 (879.0 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:06:09.561353: step 1700, loss = 1.3791 (872.0 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:06:15.398064: step 1800, loss = 1.1221 (875.4 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:06:21.244588: step 1900, loss = 1.3535 (879.7 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:06:27.071126: step 2000, loss = 1.0066 (876.3 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:06:30.873485 (2): train accuracy = 0.660 validation accuracy = 0.583\n"
     ]
    }
   ],
   "source": [
    "# 2: train it again for another epoch\n",
    "# Note the `force_restart` parameter removed.\n",
    "# `epochs` is the TOTAL number of epoch for the trained model\n",
    "# Thus since we trained it before for a single epoch,\n",
    "# we set \"epochs\": 2 in order to train it for another epoch\n",
    "\n",
    "with tf.device(device):\n",
    "    info = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar10,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 2,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.5835</td>\n",
       "      <td>0.5887</td>\n",
       "      <td>0.5835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test   train  validation\n",
       "accuracy  0.5835  0.5887      0.5835"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results in a table. Let's use a Pandas DataFrame for that\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in info[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save last trained model info\n",
    "vggInfo = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-22 11:07:22.929769: step 0, loss = 4.7206 (31.8 examples/sec; 1.575 sec/batch)\n",
      "2017-03-22 11:07:28.922326: step 100, loss = 4.6433 (870.9 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:07:34.815198: step 200, loss = 4.6456 (885.5 examples/sec; 0.056 sec/batch)\n",
      "2017-03-22 11:07:40.850390: step 300, loss = 4.6375 (622.4 examples/sec; 0.080 sec/batch)\n",
      "2017-03-22 11:07:46.978545: step 400, loss = 4.6362 (873.8 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:07:52.874105: step 500, loss = 4.6377 (875.8 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:07:58.754069: step 600, loss = 4.6313 (872.5 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:08:04.591320: step 700, loss = 4.6270 (876.2 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:08:10.469653: step 800, loss = 4.6238 (877.6 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:08:16.393702: step 900, loss = 4.6236 (874.7 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:08:22.341908: step 1000, loss = 4.6161 (877.0 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:08:26.126985 (1): train accuracy = 0.000 validation accuracy = 0.010\n"
     ]
    }
   ],
   "source": [
    "# 3: TRANSFER LEARNING\n",
    "# Use the best model trained on Cifar10, to classify Cifar 100 images.\n",
    "# Thus we train ONLY the softmax linear scope (that has 100 neurons, now),\n",
    "# keeping constant any other previosly trained layer\n",
    "# We load the weights from the previous trained model, or better\n",
    "# DyTB saves the \"best\" model (w.r.t. a metric) in a separate folder\n",
    "# So we extract the info[\"paths\"][\"best\"] path, that's the path of the best\n",
    "# model trained so far.\n",
    "cifar100 = Cifar100.Cifar100()\n",
    "with tf.device(device):\n",
    "    transferInfo = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar100,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                    }\n",
    "                }\n",
    "        },\n",
    "        force_restart=True,\n",
    "        surgery={\n",
    "            \"checkpoint_path\": vggInfo[\"paths\"][\"best\"],\n",
    "            \"exclude_scopes\": \"VGG/softmax_linear\",\n",
    "            \"trainable_scopes\": \"VGG/softmax_linear\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-22 11:09:17.863176: step 0, loss = 4.8634 (32.5 examples/sec; 1.540 sec/batch)\n",
      "2017-03-22 11:09:23.859887: step 100, loss = 4.6499 (878.9 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:09:29.753352: step 200, loss = 4.6397 (879.3 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:09:35.580706: step 300, loss = 4.6451 (879.3 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:09:41.441008: step 400, loss = 4.6383 (874.9 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:09:47.305666: step 500, loss = 4.6336 (883.6 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:09:53.173104: step 600, loss = 4.6297 (873.6 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:09:59.026746: step 700, loss = 4.6234 (882.3 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:10:04.880436: step 800, loss = 4.6228 (877.0 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:10:10.740961: step 900, loss = 4.6206 (882.8 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:10:16.586785: step 1000, loss = 4.6100 (873.6 examples/sec; 0.057 sec/batch)\n",
      "2017-03-22 11:10:20.383265 (1): train accuracy = 0.040 validation accuracy = 0.010\n"
     ]
    }
   ],
   "source": [
    "# 4: FINE TUNING:\n",
    "# Use the model pointed by vggInfo to fine tune the whole network\n",
    "# and tune it on Cifar100.\n",
    "# Let's retrain the whole network end-to-end, starting from the learned weights\n",
    "# Just remove the \"traiable_scopes\" section from the surgery parameter\n",
    "with tf.device(device):\n",
    "    fineTuningInfo = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar100,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        force_restart=True,\n",
    "        surgery={\n",
    "            \"checkpoint_path\": vggInfo[\"paths\"][\"best\"],\n",
    "            \"exclude_scopes\": \"VGG/softmax_linear\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          test   train  validation\n",
       "accuracy  0.01  0.0102        0.01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the performance of Transfer learning and Fine Tuning\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in transferInfo[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01014</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          test    train  validation\n",
       "accuracy  0.01  0.01014        0.01"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = {key: value[\"accuracy\"] for key, value in fineTuningInfo[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'args': {   'batch_size': 50,\n",
      "                'checkpoint_path': '',\n",
      "                'comment': '',\n",
      "                'dataset': <dytb.inputs.predefined.Cifar10.Cifar10 object at 0x7fe5b42f6048>,\n",
      "                'epochs': 2,\n",
      "                'exclude_scopes': '',\n",
      "                'force_restart': False,\n",
      "                'gd': {   'args': {   'beta1': 0.9,\n",
      "                                      'beta2': 0.99,\n",
      "                                      'epsilon': 1e-08,\n",
      "                                      'learning_rate': 0.001},\n",
      "                          'optimizer': <class 'tensorflow.python.training.adam.AdamOptimizer'>},\n",
      "                'lr_decay': {'enabled': False, 'epochs': 25, 'factor': 0.1},\n",
      "                'model': <dytb.models.predefined.VGG.VGG object at 0x7fe5b7bc0b00>,\n",
      "                'regularizations': {   'augmentation': <function random_flip_left_right at 0x7fe55eb84c80>,\n",
      "                                       'l2': 1e-05},\n",
      "                'trainable_scopes': ''},\n",
      "    'paths': {   'best': '/data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best',\n",
      "                 'current': '/data/pgaleone/dtb_work/examples',\n",
      "                 'log': '/data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr'},\n",
      "    'stats': {   'test': {   'accuracy': 0.58349998146295545,\n",
      "                             'confusion_matrix': array([[577,  10,  79,  14,  11,  15,  22,  29, 212,  31],\n",
      "       [  9, 685,   2,  20,   0,   5,  22,   3, 143, 111],\n",
      "       [ 77,   2, 218,  42, 173, 167, 213,  65,  37,   6],\n",
      "       [ 15,   1,  45, 253,  31, 329, 229,  67,  22,   8],\n",
      "       [ 22,   0,  41,  31, 387,  52, 301, 150,  12,   4],\n",
      "       [  5,   1,  27, 117,  36, 534, 128, 136,   9,   7],\n",
      "       [  6,   2,  14,  47,  23,  19, 879,   2,   8,   0],\n",
      "       [  9,   0,   9,  30,  40, 101,  33, 766,   1,  11],\n",
      "       [ 92,  13,  13,  33,   2,  11,   9,   8, 790,  29],\n",
      "       [ 22,  89,   0,  27,   2,  10,  24,  32,  48, 746]])},\n",
      "                 'train': {   'accuracy': 0.58869998201727869,\n",
      "                              'confusion_matrix': array([[2835,   33,  361,   80,   93,   96,  121,  190, 1066,  143],\n",
      "       [  53, 3467,   10,   41,    8,   10,   98,   14,  651,  647],\n",
      "       [ 407,    4, 1187,  328,  895,  707,  993,  320,  150,   22],\n",
      "       [  34,    6,  218, 1078,  147, 1792, 1209,  365,  133,   38],\n",
      "       [ 130,    4,  239,  142, 2054,  273, 1388,  734,   46,   13],\n",
      "       [  11,    2,  127,  675,  189, 2720,  594,  639,   30,   17],\n",
      "       [  12,   11,   62,  221,  122,  108, 4361,   25,   36,   16],\n",
      "       [  25,    0,   37,  167,  252,  503,  157, 3781,   24,   36],\n",
      "       [ 340,   59,   71,   95,    6,   59,   58,   48, 4104,  116],\n",
      "       [  97,  471,   15,  109,    4,   46,  127,  157,  244, 3741]])},\n",
      "                 'validation': {   'accuracy': 0.58349998027086258,\n",
      "                                   'confusion_matrix': array([[577,  10,  79,  14,  11,  15,  22,  29, 212,  31],\n",
      "       [  9, 685,   2,  20,   0,   5,  22,   3, 143, 111],\n",
      "       [ 77,   2, 218,  42, 173, 167, 213,  65,  37,   6],\n",
      "       [ 15,   1,  45, 253,  31, 329, 229,  67,  22,   8],\n",
      "       [ 22,   0,  41,  31, 387,  52, 301, 150,  12,   4],\n",
      "       [  5,   1,  27, 117,  36, 534, 128, 136,   9,   7],\n",
      "       [  6,   2,  14,  47,  23,  19, 879,   2,   8,   0],\n",
      "       [  9,   0,   9,  30,  40, 101,  33, 766,   1,  11],\n",
      "       [ 92,  13,  13,  33,   2,  11,   9,   8, 790,  29],\n",
      "       [ 22,  89,   0,  27,   2,  10,  24,  32,  48, 746]])}},\n",
      "    'steps': {'decay': 25000, 'epoch': 1000, 'log': 100, 'max': 2000}}\n"
     ]
    }
   ],
   "source": [
    "# For completeness, lets see what a info object contains\n",
    "pprint.pprint(info, indent=4)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
