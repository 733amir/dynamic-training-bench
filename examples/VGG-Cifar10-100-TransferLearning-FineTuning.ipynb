{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's see how to use DBT to:\n",
    "# 1: train a VGG-like network on CIFAR-10\n",
    "# 2: continue a train from the last iteration\n",
    "# 3: do TRANSFER LEARNING from the trained model to another model that will be able to classify CIFAR-100\n",
    "# 4: do FINE TUNING of the model trained on CIFAR-10 to solve the CIFAR-100 classification problem\n",
    "# 5: compare the train/validation/test performance of the models\n",
    "\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "from dytb.inputs.predefined import Cifar10, Cifar100\n",
    "from dytb.train import train\n",
    "from dytb.models.predefined.VGG import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "vgg = VGG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the CIFAR-10 input source\n",
    "cifar10 = Cifar10.Cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size 50000. Augmented training set size: 100000\n",
      "<tf.Variable 'VGG/64/conv1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv1/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/W:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/W:0' shape=(512, 10) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/b:0' shape=(10,) dtype=float32_ref>\n",
      "Model VGG: trainable parameters: 14982474. Size: 59929.896 KB\n",
      "[!] No checkpoint file found\n",
      "2017-05-10 12:39:04.987428: step 0, loss = 2.4711 (20.0 examples/sec; 2.505 sec/batch)\n",
      "2017-05-10 12:39:10.429389: step 200, loss = 2.3497 (1926.7 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:39:15.826667: step 400, loss = 2.2890 (1940.3 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:39:21.196526: step 600, loss = 1.9429 (1938.0 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:39:26.582609: step 800, loss = 1.8008 (1945.9 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:39:31.953297: step 1000, loss = 1.6698 (1929.8 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:39:37.361383: step 1200, loss = 1.7827 (1906.1 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:39:42.764955: step 1400, loss = 1.4939 (1882.0 examples/sec; 0.027 sec/batch)\n",
      "2017-05-10 12:39:48.196810: step 1600, loss = 1.4881 (1902.3 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:39:53.567176: step 1800, loss = 1.4358 (1914.9 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:39:58.906929: step 2000, loss = 1.2369 (1921.6 examples/sec; 0.026 sec/batch)\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/model.ckpt-2000\n",
      "2017-05-10 12:40:01.059430 (1): train accuracy = 0.480 validation accuracy = 0.547\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n"
     ]
    }
   ],
   "source": [
    "# 1: Train VGG on Cifar10 for an Epoch\n",
    "\n",
    "# Place the train process on GPU:0\n",
    "device = '/gpu:0'\n",
    "with tf.device(device):\n",
    "    info = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar10,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right,\n",
    "                    # On average the training set size double appling this\n",
    "                    # transformation, thus factor=2\n",
    "                    \"factor\": 2,\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        force_restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.55634</td>\n",
       "      <td>0.5468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test    train  validation\n",
       "accuracy  0.5468  0.55634      0.5468"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Info contains every information related to the trained model.\n",
    "# We're interested in stats only, thus we extract only them from the info dict\n",
    "# Display the results in a table. Let's use a Pandas DataFrame for that\n",
    "\n",
    "# Extract the accuracyes measured in every set (train/validation/test)\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in info[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2995</td>\n",
       "      <td>122</td>\n",
       "      <td>358</td>\n",
       "      <td>83</td>\n",
       "      <td>97</td>\n",
       "      <td>19</td>\n",
       "      <td>72</td>\n",
       "      <td>111</td>\n",
       "      <td>962</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>3548</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>226</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>701</td>\n",
       "      <td>3</td>\n",
       "      <td>1618</td>\n",
       "      <td>402</td>\n",
       "      <td>1022</td>\n",
       "      <td>196</td>\n",
       "      <td>700</td>\n",
       "      <td>169</td>\n",
       "      <td>90</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127</td>\n",
       "      <td>6</td>\n",
       "      <td>594</td>\n",
       "      <td>1103</td>\n",
       "      <td>287</td>\n",
       "      <td>1334</td>\n",
       "      <td>1309</td>\n",
       "      <td>132</td>\n",
       "      <td>46</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196</td>\n",
       "      <td>3</td>\n",
       "      <td>614</td>\n",
       "      <td>213</td>\n",
       "      <td>2220</td>\n",
       "      <td>72</td>\n",
       "      <td>747</td>\n",
       "      <td>883</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>446</td>\n",
       "      <td>824</td>\n",
       "      <td>316</td>\n",
       "      <td>2394</td>\n",
       "      <td>749</td>\n",
       "      <td>191</td>\n",
       "      <td>13</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>264</td>\n",
       "      <td>156</td>\n",
       "      <td>437</td>\n",
       "      <td>71</td>\n",
       "      <td>3899</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>280</td>\n",
       "      <td>437</td>\n",
       "      <td>391</td>\n",
       "      <td>333</td>\n",
       "      <td>130</td>\n",
       "      <td>3354</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>963</td>\n",
       "      <td>339</td>\n",
       "      <td>135</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>3241</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>97</td>\n",
       "      <td>805</td>\n",
       "      <td>48</td>\n",
       "      <td>136</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>261</td>\n",
       "      <td>3488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9\n",
       "0  2995   122   358    83    97    19    72   111   962   160\n",
       "1    26  3548    11    28     6     4    55     8   226  1064\n",
       "2   701     3  1618   402  1022   196   700   169    90    71\n",
       "3   127     6   594  1103   287  1334  1309   132    46    99\n",
       "4   196     3   614   213  2220    72   747   883    36    23\n",
       "5    27     2   446   824   316  2394   749   191    13    58\n",
       "6    22     7   264   156   437    71  3899    22    22    60\n",
       "7    52     4   280   437   391   333   130  3354     9    61\n",
       "8   963   339   135    60     4    28    62    15  3241   130\n",
       "9    97   805    48   136     8    18    95    65   261  3488"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the confusion matrices \n",
    "confusion_matrices = {key: value[\"confusion_matrix\"] for key, value in info[\"stats\"].items()}\n",
    "# Display the confusione matrices for the training set\n",
    "df = pd.DataFrame(confusion_matrices[\"train\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size 50000. Augmented training set size: 100000\n",
      "<tf.Variable 'VGG/64/conv1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv1/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/W:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/W:0' shape=(512, 10) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/b:0' shape=(10,) dtype=float32_ref>\n",
      "Model VGG: trainable parameters: 14982474. Size: 59929.896 KB\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "2017-05-10 12:40:35.049856: step 2200, loss = 1.0064 (1898.5 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:40:40.544264: step 2400, loss = 1.3321 (1916.9 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:40:45.966174: step 2600, loss = 1.1456 (1905.3 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:40:51.343284: step 2800, loss = 1.2027 (1920.1 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:40:56.735319: step 3000, loss = 1.0801 (1887.2 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:41:02.132182: step 3200, loss = 1.0081 (1873.7 examples/sec; 0.027 sec/batch)\n",
      "2017-05-10 12:41:07.509780: step 3400, loss = 0.7828 (1916.8 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:41:12.896908: step 3600, loss = 0.7278 (1883.4 examples/sec; 0.027 sec/batch)\n",
      "2017-05-10 12:41:18.340490: step 3800, loss = 0.7128 (1899.9 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:41:23.750772: step 4000, loss = 0.8640 (1903.6 examples/sec; 0.026 sec/batch)\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/model.ckpt-4000\n",
      "2017-05-10 12:41:25.912095 (2): train accuracy = 0.700 validation accuracy = 0.711\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n"
     ]
    }
   ],
   "source": [
    "# 2: train it again for another epoch\n",
    "# Note the `force_restart` parameter removed.\n",
    "# `epochs` is the TOTAL number of epoch for the trained model\n",
    "# Thus since we trained it before for a single epoch,\n",
    "# we set \"epochs\": 2 in order to train it for another epoch\n",
    "\n",
    "with tf.device(device):\n",
    "    info = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar10,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 2,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right,\n",
    "                    \"factor\": 2,\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.7114</td>\n",
       "      <td>0.73332</td>\n",
       "      <td>0.7114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test    train  validation\n",
       "accuracy  0.7114  0.73332      0.7114"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results in a table. Let's use a Pandas DataFrame for that\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in info[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save last trained model info\n",
    "vggInfo = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size 50000. Augmented training set size: 100000\n",
      "<tf.Variable 'VGG/64/conv1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv1/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/W:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/W:0' shape=(512, 100) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/b:0' shape=(100,) dtype=float32_ref>\n",
      "Model VGG: trainable parameters: 15028644. Size: 60114.576 KB\n",
      "[!] No checkpoint file found\n",
      "2017-05-10 12:41:55.229363: step 0, loss = 4.7865 (32.3 examples/sec; 1.547 sec/batch)\n",
      "2017-05-10 12:42:01.226177: step 200, loss = 4.6464 (1909.4 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:42:06.729397: step 400, loss = 4.6369 (1877.3 examples/sec; 0.027 sec/batch)\n",
      "2017-05-10 12:42:12.201952: step 600, loss = 4.6342 (1910.0 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:42:17.690057: step 800, loss = 4.6223 (1909.4 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:42:23.142420: step 1000, loss = 4.6175 (1891.7 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:42:28.643602: step 1200, loss = 4.6093 (1908.1 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:42:34.098332: step 1400, loss = 4.6078 (1909.1 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:42:39.496551: step 1600, loss = 4.6036 (1897.6 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:42:44.899377: step 1800, loss = 4.6014 (1902.5 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:42:50.310703: step 2000, loss = 4.6113 (1780.6 examples/sec; 0.028 sec/batch)\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/model.ckpt-2000\n",
      "2017-05-10 12:42:52.579110 (1): train accuracy = 0.000 validation accuracy = 0.010\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n"
     ]
    }
   ],
   "source": [
    "# 3: TRANSFER LEARNING\n",
    "# Use the best model trained on Cifar10, to classify Cifar 100 images.\n",
    "# Thus we train ONLY the softmax linear scope (that has 100 neurons, now),\n",
    "# keeping constant any other previosly trained layer\n",
    "# We load the weights from the previous trained model, or better\n",
    "# DyTB saves the \"best\" model (w.r.t. a metric) in a separate folder\n",
    "# So we extract the info[\"paths\"][\"best\"] path, that's the path of the best\n",
    "# model trained so far.\n",
    "cifar100 = Cifar100.Cifar100()\n",
    "with tf.device(device):\n",
    "    transferInfo = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar100,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right,\n",
    "                    \"factor\": 2,\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                    }\n",
    "                }\n",
    "        },\n",
    "        force_restart=True,\n",
    "        surgery={\n",
    "            \"checkpoint_path\": vggInfo[\"paths\"][\"best\"],\n",
    "            \"exclude_scopes\": \"VGG/softmax_linear\",\n",
    "            \"trainable_scopes\": \"VGG/softmax_linear\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size 50000. Augmented training set size: 100000\n",
      "<tf.Variable 'VGG/64/conv1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv1/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/W:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/W:0' shape=(512, 100) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/b:0' shape=(100,) dtype=float32_ref>\n",
      "Model VGG: trainable parameters: 15028644. Size: 60114.576 KB\n",
      "[!] No checkpoint file found\n",
      "2017-05-10 12:43:20.447984: step 0, loss = 4.9513 (40.7 examples/sec; 1.228 sec/batch)\n",
      "2017-05-10 12:43:26.016333: step 200, loss = 4.6430 (1912.4 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:43:31.451771: step 400, loss = 4.6353 (1872.3 examples/sec; 0.027 sec/batch)\n",
      "2017-05-10 12:43:36.916200: step 600, loss = 4.6293 (1911.4 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:43:42.348065: step 800, loss = 4.6190 (1904.1 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:43:47.822970: step 1000, loss = 4.6131 (1903.6 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:43:53.328938: step 1200, loss = 4.6075 (1910.5 examples/sec; 0.026 sec/batch)\n",
      "2017-05-10 12:43:58.777323: step 1400, loss = 4.6060 (1882.0 examples/sec; 0.027 sec/batch)\n",
      "2017-05-10 12:44:04.387092: step 1600, loss = 4.6091 (1817.7 examples/sec; 0.028 sec/batch)\n",
      "2017-05-10 12:44:09.883176: step 1800, loss = 4.6054 (1857.0 examples/sec; 0.027 sec/batch)\n",
      "2017-05-10 12:44:15.278925: step 2000, loss = 4.6057 (1899.7 examples/sec; 0.026 sec/batch)\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/model.ckpt-2000\n",
      "2017-05-10 12:44:17.414402 (1): train accuracy = 0.020 validation accuracy = 0.010\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n"
     ]
    }
   ],
   "source": [
    "# 4: FINE TUNING:\n",
    "# Use the model pointed by vggInfo to fine tune the whole network\n",
    "# and tune it on Cifar100.\n",
    "# Let's retrain the whole network end-to-end, starting from the learned weights\n",
    "# Just remove the \"traiable_scopes\" section from the surgery parameter\n",
    "with tf.device(device):\n",
    "    fineTuningInfo = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar100,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right,\n",
    "                    \"factor\": 2,\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        force_restart=True,\n",
    "        surgery={\n",
    "            \"checkpoint_path\": vggInfo[\"paths\"][\"best\"],\n",
    "            \"exclude_scopes\": \"VGG/softmax_linear\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01002</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          test    train  validation\n",
       "accuracy  0.01  0.01002        0.01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the performance of Transfer learning and Fine Tuning\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in transferInfo[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00984</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          test    train  validation\n",
       "accuracy  0.01  0.00984        0.01"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = {key: value[\"accuracy\"] for key, value in fineTuningInfo[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'args': {   'batch_size': 50,\n",
      "                'checkpoint_path': '',\n",
      "                'comment': '',\n",
      "                'dataset': <dytb.inputs.predefined.Cifar10.Cifar10 object at 0x7fa60c662588>,\n",
      "                'epochs': 2,\n",
      "                'exclude_scopes': None,\n",
      "                'force_restart': False,\n",
      "                'gd': {   'args': {   'beta1': 0.9,\n",
      "                                      'beta2': 0.99,\n",
      "                                      'epsilon': 1e-08,\n",
      "                                      'learning_rate': 0.001},\n",
      "                          'optimizer': <class 'tensorflow.python.training.adam.AdamOptimizer'>},\n",
      "                'lr_decay': {'enabled': False, 'epochs': 25, 'factor': 0.1},\n",
      "                'model': <dytb.models.predefined.VGG.VGG object at 0x7fa60c6624e0>,\n",
      "                'regularizations': {   'augmentation': {   'factor': 2,\n",
      "                                                           'fn': <function random_flip_left_right at 0x7fa5b6f1c730>,\n",
      "                                                           'name': 'FlipLR'},\n",
      "                                       'l2': 1e-05},\n",
      "                'seed': None,\n",
      "                'trainable_scopes': None},\n",
      "    'paths': {   'best': '/data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best',\n",
      "                 'current': '/data/pgaleone/dtb_work/examples',\n",
      "                 'log': '/data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr'},\n",
      "    'stats': {   'test': {   'accuracy': 0.71139998286962514,\n",
      "                             'confusion_matrix': array([[623,   3, 127,  21,  92,   2,  18,  11,  86,  17],\n",
      "       [  9, 824,   3,  13,   3,   4,  21,   0,  73,  50],\n",
      "       [ 35,   0, 563,  68, 106, 100,  85,  30,  10,   3],\n",
      "       [  6,   0,  73, 482,  47, 261,  95,  21,   8,   7],\n",
      "       [  3,   1,  78,  56, 687,  37,  76,  56,   5,   1],\n",
      "       [  3,   0,  37, 147,  38, 711,  24,  40,   0,   0],\n",
      "       [  1,   0,  29,  67,  18,  21, 859,   0,   5,   0],\n",
      "       [  7,   0,  31,  48,  59,  67,   4, 781,   2,   1],\n",
      "       [ 75,   7,  23,  25,  12,   5,  13,   2, 828,  10],\n",
      "       [ 27, 115,   3,  44,   3,   0,  22,   6,  24, 756]])},\n",
      "                 'train': {   'accuracy': 0.73331998401880261,\n",
      "                              'confusion_matrix': array([[3210,   24,  666,  104,  404,   21,   50,   79,  344,   78],\n",
      "       [  56, 4213,   15,   44,    8,    5,  120,    3,  321,  179],\n",
      "       [ 123,    2, 3154,  327,  486,  369,  501,   75,   41,    6],\n",
      "       [  22,    1,  298, 2485,  208, 1475,  370,  111,   34,   13],\n",
      "       [  28,    1,  310,  232, 3666,  181,  315,  259,   12,    1],\n",
      "       [   9,    0,  175,  669,  174, 3561,  129,  251,    7,    9],\n",
      "       [   6,    4,  143,  341,  110,   92, 4243,    6,   19,    1],\n",
      "       [  21,    0,  148,  164,  307,  359,   19, 3972,    6,   13],\n",
      "       [ 281,   46,  124,  106,   19,    8,   56,    6, 4328,   27],\n",
      "       [ 115,  600,   13,  209,   19,   12,   95,   17,  110, 3801]])},\n",
      "                 'validation': {   'accuracy': 0.71139998435974117,\n",
      "                                   'confusion_matrix': array([[623,   3, 127,  21,  92,   2,  18,  11,  86,  17],\n",
      "       [  9, 824,   3,  13,   3,   4,  21,   0,  73,  50],\n",
      "       [ 35,   0, 563,  68, 106, 100,  85,  30,  10,   3],\n",
      "       [  6,   0,  73, 482,  47, 261,  95,  21,   8,   7],\n",
      "       [  3,   1,  78,  56, 687,  37,  76,  56,   5,   1],\n",
      "       [  3,   0,  37, 147,  38, 711,  24,  40,   0,   0],\n",
      "       [  1,   0,  29,  67,  18,  21, 859,   0,   5,   0],\n",
      "       [  7,   0,  31,  48,  59,  67,   4, 781,   2,   1],\n",
      "       [ 75,   7,  23,  25,  12,   5,  13,   2, 828,  10],\n",
      "       [ 27, 115,   3,  44,   3,   0,  22,   6,  24, 756]])}},\n",
      "    'steps': {'decay': 50000, 'epoch': 2000, 'log': 200, 'max': 4000}}\n"
     ]
    }
   ],
   "source": [
    "# For completeness, lets see what a info object contains\n",
    "pprint.pprint(info, indent=4)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
