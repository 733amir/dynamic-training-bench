{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's see how to use DBT to:\n",
    "# 1: train a VGG-like network on CIFAR-10\n",
    "# 2: continue a train from the last iteration\n",
    "# 3: do TRANSFER LEARNING from the trained model to another model that will be able to classify CIFAR-100\n",
    "# 4: do FINE TUNING of the model trained on CIFAR-10 to solve the CIFAR-100 classification problem\n",
    "# 5: compare the train/validation/test performance of the models\n",
    "\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "from dytb.inputs.predefined import Cifar10, Cifar100\n",
    "from dytb.train import train\n",
    "from dytb.models.predefined.VGG import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "vgg = VGG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the CIFAR-10 input source\n",
    "cifar10 = Cifar10.Cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size 50000. Augmented training set size: 100000\n",
      "<tf.Variable 'VGG/64/conv1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv1/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/W:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/W:0' shape=(512, 10) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/b:0' shape=(10,) dtype=float32_ref>\n",
      "Model VGG: trainable parameters: 14982474. Size: 59929.896 KB\n",
      "[!] No checkpoint file found\n",
      "2017-05-09 10:01:12.437408: step 0, loss = 2.4819 (16.4 examples/sec; 3.044 sec/batch)\n",
      "2017-05-09 10:01:24.974146: step 200, loss = 2.1332 (807.4 examples/sec; 0.062 sec/batch)\n",
      "2017-05-09 10:01:37.342148: step 400, loss = 2.2142 (770.4 examples/sec; 0.065 sec/batch)\n",
      "2017-05-09 10:01:49.726940: step 600, loss = 1.6325 (852.4 examples/sec; 0.059 sec/batch)\n",
      "2017-05-09 10:02:02.034342: step 800, loss = 1.6711 (850.6 examples/sec; 0.059 sec/batch)\n",
      "2017-05-09 10:02:14.602236: step 1000, loss = 1.3169 (777.6 examples/sec; 0.064 sec/batch)\n",
      "2017-05-09 10:02:27.047268: step 1200, loss = 1.2873 (811.6 examples/sec; 0.062 sec/batch)\n",
      "2017-05-09 10:02:39.494747: step 1400, loss = 1.3084 (825.2 examples/sec; 0.061 sec/batch)\n",
      "2017-05-09 10:02:51.998904: step 1600, loss = 1.3426 (849.8 examples/sec; 0.059 sec/batch)\n",
      "2017-05-09 10:03:04.467529: step 1800, loss = 1.1737 (853.9 examples/sec; 0.059 sec/batch)\n",
      "2017-05-09 10:03:16.995562: step 2000, loss = 1.0822 (832.1 examples/sec; 0.060 sec/batch)\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/model.ckpt-2000\n",
      "2017-05-09 10:03:22.574417 (1): train accuracy = 0.720 validation accuracy = 0.635\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n"
     ]
    }
   ],
   "source": [
    "# 1: Train VGG on Cifar10 for an Epoch\n",
    "\n",
    "# Place the train process on GPU:0\n",
    "device = '/gpu:0'\n",
    "with tf.device(device):\n",
    "    info = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar10,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right,\n",
    "                    # On average the training set size double appling this\n",
    "                    # transformation, thus factor=2\n",
    "                    \"factor\": 2,\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        force_restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.6351</td>\n",
       "      <td>0.64872</td>\n",
       "      <td>0.635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test    train  validation\n",
       "accuracy  0.6351  0.64872       0.635"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Info contains every information related to the trained model.\n",
    "# We're interested in stats only, thus we extract only them from the info dict\n",
    "# Display the results in a table. Let's use a Pandas DataFrame for that\n",
    "\n",
    "# Extract the accuracyes measured in every set (train/validation/test)\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in info[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3258</td>\n",
       "      <td>116</td>\n",
       "      <td>373</td>\n",
       "      <td>55</td>\n",
       "      <td>72</td>\n",
       "      <td>69</td>\n",
       "      <td>21</td>\n",
       "      <td>136</td>\n",
       "      <td>826</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>4201</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>121</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>383</td>\n",
       "      <td>8</td>\n",
       "      <td>2249</td>\n",
       "      <td>187</td>\n",
       "      <td>841</td>\n",
       "      <td>562</td>\n",
       "      <td>394</td>\n",
       "      <td>166</td>\n",
       "      <td>127</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "      <td>510</td>\n",
       "      <td>809</td>\n",
       "      <td>356</td>\n",
       "      <td>2179</td>\n",
       "      <td>658</td>\n",
       "      <td>196</td>\n",
       "      <td>120</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>524</td>\n",
       "      <td>69</td>\n",
       "      <td>2846</td>\n",
       "      <td>257</td>\n",
       "      <td>360</td>\n",
       "      <td>705</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>321</td>\n",
       "      <td>317</td>\n",
       "      <td>282</td>\n",
       "      <td>3646</td>\n",
       "      <td>136</td>\n",
       "      <td>225</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>157</td>\n",
       "      <td>251</td>\n",
       "      <td>402</td>\n",
       "      <td>150</td>\n",
       "      <td>3822</td>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>73</td>\n",
       "      <td>290</td>\n",
       "      <td>754</td>\n",
       "      <td>23</td>\n",
       "      <td>3567</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>324</td>\n",
       "      <td>188</td>\n",
       "      <td>67</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>4194</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>129</td>\n",
       "      <td>570</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>235</td>\n",
       "      <td>120</td>\n",
       "      <td>3859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2    3     4     5     6     7     8     9\n",
       "0  3258   116   373   55    72    69    21   136   826   123\n",
       "1    36  4201     8   28    13     6    27    28   121   544\n",
       "2   383     8  2249  187   841   562   394   166   127    20\n",
       "3    82    12   510  809   356  2179   658   196   120   105\n",
       "4   155     8   524   69  2846   257   360   705    32    24\n",
       "5    29     5   321  317   282  3646   136   225    24    22\n",
       "6    16    16   157  251   402   150  3822    22    33   120\n",
       "7    54     0   156   73   290   754    23  3567    18    14\n",
       "8   324   188    67   43    11    20    31    32  4194    90\n",
       "9   129   570    15   48     9    53    12   235   120  3859"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the confusion matrices \n",
    "confusion_matrices = {key: value[\"confusion_matrix\"] for key, value in info[\"stats\"].items()}\n",
    "# Display the confusione matrices for the training set\n",
    "df = pd.DataFrame(confusion_matrices[\"train\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size 50000. Augmented training set size: 100000\n",
      "<tf.Variable 'VGG/64/conv1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv1/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/W:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/W:0' shape=(512, 10) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/b:0' shape=(10,) dtype=float32_ref>\n",
      "Model VGG: trainable parameters: 14982474. Size: 59929.896 KB\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "2017-05-09 10:04:54.639023: step 2200, loss = 1.0208 (833.1 examples/sec; 0.060 sec/batch)\n",
      "2017-05-09 10:05:07.225772: step 2400, loss = 0.9995 (860.2 examples/sec; 0.058 sec/batch)\n",
      "2017-05-09 10:05:19.765520: step 2600, loss = 0.7871 (714.3 examples/sec; 0.070 sec/batch)\n",
      "2017-05-09 10:05:32.295583: step 2800, loss = 1.3104 (808.7 examples/sec; 0.062 sec/batch)\n",
      "2017-05-09 10:05:44.878714: step 3000, loss = 1.1861 (865.2 examples/sec; 0.058 sec/batch)\n",
      "2017-05-09 10:05:57.334117: step 3200, loss = 0.8017 (821.6 examples/sec; 0.061 sec/batch)\n",
      "2017-05-09 10:06:09.886928: step 3400, loss = 0.7264 (818.1 examples/sec; 0.061 sec/batch)\n",
      "2017-05-09 10:06:22.441781: step 3600, loss = 0.6490 (795.1 examples/sec; 0.063 sec/batch)\n",
      "2017-05-09 10:06:34.958385: step 3800, loss = 0.5916 (781.3 examples/sec; 0.064 sec/batch)\n",
      "2017-05-09 10:06:47.498855: step 4000, loss = 1.3147 (789.3 examples/sec; 0.063 sec/batch)\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/model.ckpt-4000\n",
      "2017-05-09 10:06:52.759158 (2): train accuracy = 0.680 validation accuracy = 0.731\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-10_Adam_l2=1e-05_fliplr/best/model.ckpt-4000\n"
     ]
    }
   ],
   "source": [
    "# 2: train it again for another epoch\n",
    "# Note the `force_restart` parameter removed.\n",
    "# `epochs` is the TOTAL number of epoch for the trained model\n",
    "# Thus since we trained it before for a single epoch,\n",
    "# we set \"epochs\": 2 in order to train it for another epoch\n",
    "\n",
    "with tf.device(device):\n",
    "    info = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar10,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 2,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right,\n",
    "                    \"factor\": 2,\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.7314</td>\n",
       "      <td>0.75866</td>\n",
       "      <td>0.7314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            test    train  validation\n",
       "accuracy  0.7314  0.75866      0.7314"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results in a table. Let's use a Pandas DataFrame for that\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in info[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save last trained model info\n",
    "vggInfo = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size 50000. Augmented training set size: 100000\n",
      "<tf.Variable 'VGG/64/conv1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv1/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/W:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/W:0' shape=(512, 100) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/b:0' shape=(100,) dtype=float32_ref>\n",
      "Model VGG: trainable parameters: 15028644. Size: 60114.576 KB\n",
      "[!] No checkpoint file found\n",
      "2017-05-09 10:08:11.612195: step 0, loss = 4.9965 (19.4 examples/sec; 2.582 sec/batch)\n",
      "2017-05-09 10:08:24.392179: step 200, loss = 4.6449 (833.5 examples/sec; 0.060 sec/batch)\n",
      "2017-05-09 10:08:36.959601: step 400, loss = 4.6348 (871.3 examples/sec; 0.057 sec/batch)\n",
      "2017-05-09 10:08:49.582174: step 600, loss = 4.6307 (833.7 examples/sec; 0.060 sec/batch)\n",
      "2017-05-09 10:09:02.232363: step 800, loss = 4.6223 (787.9 examples/sec; 0.063 sec/batch)\n",
      "2017-05-09 10:09:14.895482: step 1000, loss = 4.6145 (769.1 examples/sec; 0.065 sec/batch)\n",
      "2017-05-09 10:09:27.502048: step 1200, loss = 4.6109 (869.0 examples/sec; 0.058 sec/batch)\n",
      "2017-05-09 10:09:40.125272: step 1400, loss = 4.6063 (836.7 examples/sec; 0.060 sec/batch)\n",
      "2017-05-09 10:09:52.729979: step 1600, loss = 4.6055 (864.9 examples/sec; 0.058 sec/batch)\n",
      "2017-05-09 10:10:05.286685: step 1800, loss = 4.6083 (838.6 examples/sec; 0.060 sec/batch)\n",
      "2017-05-09 10:10:17.895517: step 2000, loss = 4.6021 (843.3 examples/sec; 0.059 sec/batch)\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/model.ckpt-2000\n",
      "2017-05-09 10:10:23.651625 (1): train accuracy = 0.000 validation accuracy = 0.010\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n"
     ]
    }
   ],
   "source": [
    "# 3: TRANSFER LEARNING\n",
    "# Use the best model trained on Cifar10, to classify Cifar 100 images.\n",
    "# Thus we train ONLY the softmax linear scope (that has 100 neurons, now),\n",
    "# keeping constant any other previosly trained layer\n",
    "# We load the weights from the previous trained model, or better\n",
    "# DyTB saves the \"best\" model (w.r.t. a metric) in a separate folder\n",
    "# So we extract the info[\"paths\"][\"best\"] path, that's the path of the best\n",
    "# model trained so far.\n",
    "cifar100 = Cifar100.Cifar100()\n",
    "with tf.device(device):\n",
    "    transferInfo = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar100,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right,\n",
    "                    \"factor\": 2,\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                    }\n",
    "                }\n",
    "        },\n",
    "        force_restart=True,\n",
    "        surgery={\n",
    "            \"checkpoint_path\": vggInfo[\"paths\"][\"best\"],\n",
    "            \"exclude_scopes\": \"VGG/softmax_linear\",\n",
    "            \"trainable_scopes\": \"VGG/softmax_linear\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size 50000. Augmented training set size: 100000\n",
      "<tf.Variable 'VGG/64/conv1/W:0' shape=(3, 3, 3, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv1/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/W:0' shape=(3, 3, 64, 64) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/64/conv2/b:0' shape=(64,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/W:0' shape=(3, 3, 64, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv3/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/W:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/128/conv4/b:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/W:0' shape=(3, 3, 128, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv5/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv6/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/W:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/256/conv7/b:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/W:0' shape=(3, 3, 256, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv8/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv9/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512/conv10/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv11/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv12/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/W:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/512b2/conv13/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/W:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/fc/b:0' shape=(512,) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/W:0' shape=(512, 100) dtype=float32_ref>\n",
      "<tf.Variable 'VGG/softmax_linear/b:0' shape=(100,) dtype=float32_ref>\n",
      "Model VGG: trainable parameters: 15028644. Size: 60114.576 KB\n",
      "[!] No checkpoint file found\n",
      "2017-05-09 10:11:42.602142: step 0, loss = 4.9073 (19.3 examples/sec; 2.597 sec/batch)\n",
      "2017-05-09 10:11:55.262147: step 200, loss = 4.6435 (810.3 examples/sec; 0.062 sec/batch)\n",
      "2017-05-09 10:12:07.830382: step 400, loss = 4.6377 (850.7 examples/sec; 0.059 sec/batch)\n",
      "2017-05-09 10:12:20.431077: step 600, loss = 4.6285 (826.3 examples/sec; 0.061 sec/batch)\n",
      "2017-05-09 10:12:33.037674: step 800, loss = 4.6217 (868.1 examples/sec; 0.058 sec/batch)\n",
      "2017-05-09 10:12:45.678028: step 1000, loss = 4.6149 (775.2 examples/sec; 0.064 sec/batch)\n",
      "2017-05-09 10:12:58.293034: step 1200, loss = 4.6079 (761.5 examples/sec; 0.066 sec/batch)\n",
      "2017-05-09 10:13:10.914667: step 1400, loss = 4.6088 (845.0 examples/sec; 0.059 sec/batch)\n",
      "2017-05-09 10:13:23.560494: step 1600, loss = 4.6059 (771.2 examples/sec; 0.065 sec/batch)\n",
      "2017-05-09 10:13:36.258823: step 1800, loss = 4.6011 (802.0 examples/sec; 0.062 sec/batch)\n",
      "2017-05-09 10:13:48.711807: step 2000, loss = 4.6081 (811.7 examples/sec; 0.062 sec/batch)\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/model.ckpt-2000\n",
      "2017-05-09 10:13:54.224094 (1): train accuracy = 0.000 validation accuracy = 0.010\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n",
      "INFO:tensorflow:Restoring parameters from /data/pgaleone/dtb_work/examples/log/VGG/CIFAR-100_Adam_l2=1e-05_fliplr/best/model.ckpt-2000\n"
     ]
    }
   ],
   "source": [
    "# 4: FINE TUNING:\n",
    "# Use the model pointed by vggInfo to fine tune the whole network\n",
    "# and tune it on Cifar100.\n",
    "# Let's retrain the whole network end-to-end, starting from the learned weights\n",
    "# Just remove the \"traiable_scopes\" section from the surgery parameter\n",
    "with tf.device(device):\n",
    "    fineTuningInfo = train(\n",
    "        model=vgg,\n",
    "        dataset=cifar100,\n",
    "        hyperparameters={\n",
    "            \"epochs\": 1,\n",
    "            \"batch_size\": 50,\n",
    "            \"regularizations\": {\n",
    "                \"l2\": 1e-5,\n",
    "                \"augmentation\": {\n",
    "                    \"name\": \"FlipLR\",\n",
    "                    \"fn\": tf.image.random_flip_left_right,\n",
    "                    \"factor\": 2,\n",
    "                }\n",
    "            },\n",
    "            \"gd\": {\n",
    "                \"optimizer\": tf.train.AdamOptimizer,\n",
    "                \"args\": {\n",
    "                    \"learning_rate\": 1e-3,\n",
    "                    \"beta1\": 0.9,\n",
    "                    \"beta2\": 0.99,\n",
    "                    \"epsilon\": 1e-8\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        force_restart=True,\n",
    "        surgery={\n",
    "            \"checkpoint_path\": vggInfo[\"paths\"][\"best\"],\n",
    "            \"exclude_scopes\": \"VGG/softmax_linear\"\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compare the performance of Transfer learning and Fine Tuning\n",
    "accuracies = {key: value[\"accuracy\"] for key, value in transferInfo[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "accuracies = {key: value[\"accuracy\"] for key, value in fineTuningInfo[\"stats\"].items()}\n",
    "df = pd.DataFrame.from_records(accuracies, index=[\"accuracy\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For completeness, lets see what a info object contains\n",
    "pprint.pprint(info, indent=4)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
